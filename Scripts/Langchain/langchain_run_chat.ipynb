{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fiberta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pinecone\\data\\index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from pinecone import Pinecone\n",
    "from tqdm.autonotebook import tqdm\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.vectorstores import Pinecone as LPPinecone\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fiberta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.vectorstores.pinecone.Pinecone` was deprecated in langchain-community 0.0.18 and will be removed in 0.2.0. An updated version of the class exists in the langchain-pinecone package and should be used instead. To use it run `pip install -U langchain-pinecone` and import as `from langchain_pinecone import Pinecone`.\n",
      "  warn_deprecated(\n",
      "C:\\Users\\Fiberta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain_community\\vectorstores\\pinecone.py:68: UserWarning: Passing in `embedding` as a Callable is deprecated. Please pass in an Embeddings object instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# initialize connection to pinecone (get API key at app.pinecone.io)\n",
    "api_key = os.environ.get('PINECONE_API_KEY') or '3e81b5e5-edfe-49bf-a6ee-7ff0a9d47ca2'\n",
    "\n",
    "# configure client\n",
    "pc = Pinecone(api_key=api_key)\n",
    "\n",
    "model_name = 'text-embedding-ada-002'\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "embed = OpenAIEmbeddings(\n",
    "    model=model_name,\n",
    "    openai_api_key=os.environ['OPENAI_API_KEY']\n",
    ")\n",
    "\n",
    "index_name = 'pilot'\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "text_field = \"text\"  # the metadata field that contains our text\n",
    "vectorstore = LPPinecone(\n",
    "    index, embed.embed_query, text_field\n",
    ")\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    openai_api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    model_name='gpt-3.5-turbo',\n",
    "    temperature=0.0\n",
    ")\n",
    "\n",
    "# conversational memory\n",
    "conversational_memory = ConversationBufferWindowMemory(\n",
    "    memory_key='chat_history',\n",
    "    k=5,\n",
    "    return_messages=True\n",
    ")\n",
    "qa_with_sources = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "    llm=chat,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vectorstore.as_retriever()\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name='Knowledge Base',\n",
    "        func=qa_with_sources,\n",
    "        description=(\n",
    "            'use this tool when answering general knowledge queries to get '\n",
    "            'more information about the topic'\n",
    "        )\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fiberta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import initialize_agent\n",
    "\n",
    "agent = initialize_agent(\n",
    "    agent='chat-conversational-react-description',\n",
    "    tools=tools,\n",
    "    llm=chat,\n",
    "    verbose=True,\n",
    "    max_iterations=3,\n",
    "    early_stopping_method='generate',\n",
    "    memory=conversational_memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fiberta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Knowledge Base\",\n",
      "    \"action_input\": \"Bill Gates\"\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m{'question': 'Bill Gates', 'answer': \"I don't know.\\n\", 'sources': ''}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"Bill Gates is a co-founder of Microsoft and a prominent figure in the technology industry.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Who is bill gates?',\n",
       " 'chat_history': [],\n",
       " 'output': 'Bill Gates is a co-founder of Microsoft and a prominent figure in the technology industry.'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Who is bill gates?\"\n",
    "agent(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "def count_tokens(agent, query):\n",
    "    with get_openai_callback() as cb:\n",
    "        result = agent(query)\n",
    "        print(f'Spent a total of {cb.total_tokens} tokens')\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Knowledge Base\",\n",
      "    \"action_input\": \"Calculate the compound interest on an investment of $10,000 growing at 8% annually for 5 years\"\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m{'question': 'Calculate the compound interest on an investment of $10,000 growing at 8% annually for 5 years', 'answer': \"I don't know the answer.\\n\", 'sources': ''}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"The tool was unable to provide the answer to the compound interest calculation on an investment of $10,000 growing at 8% annually for 5 years.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Spent a total of 4027 tokens\n"
     ]
    }
   ],
   "source": [
    "\n",
    "result = count_tokens(\n",
    "    agent,\n",
    "    \"What's the result of an investment of $10,000 growing at 8% annually for 5 years with compound interest?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New test example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# MEMORY_KEY = \"chat_history\"\n",
    "# prompt = ChatPromptTemplate.from_messages(\n",
    "#     [\n",
    "#         (\n",
    "#             \"system\",\n",
    "#             \"You are very powerful assistant, but bad at calculating lengths of words.\",\n",
    "#         ),\n",
    "#         MessagesPlaceholder(variable_name=MEMORY_KEY),\n",
    "#         (\"user\", \"{input}\"),\n",
    "#         MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "# chat_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.agents import Tool\n",
    "\n",
    "# tools = [\n",
    "#     Tool(\n",
    "#         name='Knowledge Base',\n",
    "#         func=qa_with_sources,\n",
    "#         description=(\n",
    "#             'use this tool when answering general knowledge queries to get '\n",
    "#             'more information about the topic'\n",
    "#         )\n",
    "#     )\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.agents.format_scratchpad.openai_tools import (\n",
    "#     format_to_openai_tool_messages)\n",
    "# from langchain.agents.output_parsers.openai_tools import OpenAIToolsAgentOutputParser\n",
    "# from langchain.agents import AgentExecutor\n",
    "\n",
    "\n",
    "# agent = (\n",
    "#     {\n",
    "#         \"input\": lambda x: x[\"input\"],\n",
    "#         \"agent_scratchpad\": lambda x: format_to_openai_tool_messages(\n",
    "#             x[\"intermediate_steps\"]\n",
    "#         ),\n",
    "#         \"chat_history\": lambda x: x[\"chat_history\"],\n",
    "#     }\n",
    "#     | prompt\n",
    "#     | tools\n",
    "#     | OpenAIToolsAgentOutputParser()\n",
    "# )\n",
    "# agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
